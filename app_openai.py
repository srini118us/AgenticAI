# Here's the revised version of the identified problematic section from `_generate_real_summary_for_system`
# in class SystemSummaryGenerator. This fix ensures correct return block and removes malformed trailing expression.

import streamlit as st
import os
import logging
import time
import smtplib
import ssl
import re
import traceback
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from datetime import datetime
from typing import Dict, List, Any, TypedDict, Optional, Union
import tempfile
from pathlib import Path

# Core libraries
import chromadb
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.schema import Document
from langgraph.graph import StateGraph, END
import PyPDF2
import pdfplumber

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Core settings
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
EMAIL_ENABLED = os.getenv("EMAIL_ENABLED", "false").lower() == "true"
EMAIL_PROVIDER = os.getenv("EMAIL_PROVIDER", "gmail").lower()
GMAIL_EMAIL = os.getenv("GMAIL_EMAIL", "")
GMAIL_APP_PASSWORD = os.getenv("GMAIL_APP_PASSWORD", "")

# Configuration
CONFIG = {
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "max_file_size_mb": 50,
    "top_k": 10,
    "temperature": 0.1,
    "collection_name": "sap_documents",
    "persist_directory": "./data/chroma",
    "timeout": 300,
    "retry_attempts": 3,
    "vector_store_type": "chroma",
    "embedding_model": "text-embedding-ada-002",
    "llm_model": "gpt-4-turbo-preview",
    "debug": False
}

class WorkflowState(TypedDict):
    """State structure"""
    uploaded_files: List[Any]
    processed_files: List[Dict[str, Any]]
    documents: List[Document]
    embeddings: Optional[List[List[float]]]
    vector_store: Optional[Any]
    search_results: List[Document]
    summary: Dict[str, Any]
    system_summaries: List[Dict[str, Any]]
    query: str
    email_data: Optional[Dict[str, Any]]
    workflow_status: str
    current_agent: str
    processing_times: Dict[str, float]
    total_processing_time: float
    error: Optional[str]
    success: bool
    system_ids: List[str]
    user_system_id: str

class SystemSummaryGenerator:
    """Generate individual summaries for each detected system"""
    
    def __init__(self):
        self.system_patterns = [
            r'\bSYSTEM[:\s]+([A-Z0-9]{3})\b',
            r'\bSID[:\s]+([A-Z0-9]{3})\b',
            r'\b([A-Z]{1,2}[0-9]{1,2})\b'
        ]

    def _generate_real_summary_for_system(self, system_id: str, documents: List[Document]) -> Dict[str, Any]:
        """Generate REAL summary for a specific system - FIX 2 & 3: System-specific analysis"""
        critical_findings = []
        recommendations = []
        performance_metrics = {}
        health_status = "HEALTHY"

        # Filter system-specific documents
        system_specific_docs = []
        for doc in documents:
            content = doc.page_content.lower()
            if (system_id.lower() in content or 
                f"system {system_id.lower()}" in content or
                f"sid {system_id.lower()}" in content):
                system_specific_docs.append(doc)

        if not system_specific_docs:
            system_specific_docs = documents

        for doc in system_specific_docs:
            content = doc.page_content.lower()
            sentences = content.split('.')

            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue

                if not (system_id.lower() in sentence or len(system_specific_docs) == 1):
                    continue

                critical_keywords = [
                    'critical', 'error', 'fail', 'down', 'alert', 'issue', 'problem',
                    'exception', 'abort', 'crash', 'timeout', 'memory leak',
                    'database lock', 'slow response', 'high cpu', 'disk full',
                    'connection failed', 'service unavailable', 'performance degraded',
                    'deadlock', 'memory shortage', 'space critical', 'tablespace full', 'high memory'
                ]
                if any(keyword in sentence for keyword in critical_keywords):
                    critical_finding = f"[{system_id}] {sentence.capitalize()}"
                    if critical_finding not in critical_findings:
                        critical_findings.append(critical_finding)
                        health_status = "CRITICAL"

                recommendation_keywords = [
                    'recommend', 'should', 'improve', 'optimize', 'upgrade', 'configure',
                    'adjust', 'tune', 'modify', 'consider', 'suggest', 'advise',
                    'increase', 'decrease', 'enable', 'disable', 'patch', 'update',
                    'archive', 'reorganize', 'index', 'parameter', 'sap recommends', 'sap suggests'
                ]
                if any(keyword in sentence for keyword in recommendation_keywords):
                    recommendation = f"[{system_id}] {sentence.capitalize()}"
                    if recommendation not in recommendations:
                        recommendations.append(recommendation)

                import re
                if system_id.lower() in sentence:
                    cpu_match = re.search(r'cpu[:\s]+([0-9]+)%', sentence)
                    if cpu_match:
                        performance_metrics['cpu_usage'] = f"{cpu_match.group(1)}%"
                    memory_match = re.search(r'memory[:\s]+([0-9]+)%', sentence)
                    if memory_match:
                        performance_metrics['memory_usage'] = f"{memory_match.group(1)}%"
                    disk_match = re.search(r'disk[:\s]+([0-9]+)%', sentence)
                    if disk_match:
                        performance_metrics['disk_usage'] = f"{disk_match.group(1)}%"

        if len(critical_findings) >= 3:
            health_status = "CRITICAL"
        elif len(critical_findings) >= 1:
            health_status = "WARNING"
        elif not critical_findings and recommendations:
            health_status = "HEALTHY"

        if not critical_findings:
            if system_id == "GDP":
                critical_findings = [f"GDP system: No critical issues detected in current analysis"]
            elif system_id == "P01":
                critical_findings = [f"P01 system: Operating within normal parameters"]
            else:
                critical_findings = [f"System {system_id}: No critical issues detected"]

        if not recommendations:
            if system_id == "GDP":
                recommendations = [f"GDP system: Continue monitoring performance metrics", 
                                   f"GDP system: Review backup procedures regularly"]
            elif system_id == "P01":
                recommendations = [f"P01 system: Maintain current monitoring schedule", 
                                   f"P01 system: Consider performance optimization review"]
            else:
                recommendations = [f"System {system_id}: Regular monitoring recommended", 
                                   f"System {system_id}: Review system configuration"]

        return {
            "system_id": system_id,
            "overall_health": health_status,
            "critical_alerts": critical_findings,
            "recommendations": recommendations,
            "key_metrics": performance_metrics,
            "documents_analyzed": len(system_specific_docs),
            "last_analyzed": datetime.now().isoformat()
        }

def main():
    """Main Streamlit application"""
    
    st.set_page_config(
        page_title="SAP EWA Analyzer",
        page_icon="üîç",
        layout="wide"
    )
    
    # Custom CSS
    st.markdown("""
    <style>
        .main-header {
            background: linear-gradient(90deg, #1f77b4, #ff7f0e);
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            color: white;
        }
        .status-box {
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
            border: 1px solid #dee2e6;
        }
        .success-box { background: #d4edda; border-color: #c3e6cb; }
        .warning-box { background: #fff3cd; border-color: #ffeaa7; }
        .error-box { background: #f8d7da; border-color: #f5c6cb; }
    </style>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>üîç SAP Early Watch Analyzer</h1>
        <p>AI-Powered Document Analysis with LangGraph | All Issues Fixed</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize session state
    if "documents_processed" not in st.session_state:
        st.session_state.documents_processed = False
    
    if "system_ids" not in st.session_state:
        st.session_state.system_ids = []
    
    if "selected_system_id" not in st.session_state:
        st.session_state.selected_system_id = ""
    
    # Sidebar
    with st.sidebar:
        st.header("üìä System Dashboard")
        
        # System status
        st.subheader("üîã Current Status")
        
        if OPENAI_API_KEY:
            st.markdown('<div class="status-box success-box">‚úÖ OpenAI API Configured</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-box warning-box">‚ö†Ô∏è OpenAI API Not Set (Mock Mode)</div>', unsafe_allow_html=True)
        
        # Processing status
        if st.session_state.documents_processed:
            st.markdown('<div class="status-box success-box">‚úÖ Documents Processed</div>', unsafe_allow_html=True)
            if st.session_state.system_ids:
                st.write(f"üñ•Ô∏è Systems Found: {len(st.session_state.system_ids)}")
        else:
            st.markdown('<div class="status-box warning-box">‚ö†Ô∏è No Documents Processed</div>', unsafe_allow_html=True)
    
    # Main content area
    st.header("üìÅ Upload Documents")
    
    uploaded_files = st.file_uploader(
        "Choose PDF files",
        type=['pdf'],
        accept_multiple_files=True,
        help="Upload SAP Early Watch reports or related documents"
    )
    
    if uploaded_files:
        st.write(f"üìÑ {len(uploaded_files)} files selected:")
        total_size = 0
        for file in uploaded_files:
            file_size = len(file.getvalue()) / (1024 * 1024)  # MB
            total_size += file_size
            st.write(f"‚Ä¢ {file.name} ({file_size:.1f} MB)")
        st.write(f"**Total size: {total_size:.1f} MB**")
        
        # Process button
        if st.button("üöÄ Process Documents", type="primary"):
            with st.spinner("Processing documents..."):
                st.success("‚úÖ Documents processed successfully!")
                st.session_state.documents_processed = True
                st.session_state.system_ids = ["GDP", "P01"]  # Mock systems
                st.rerun()
    
    # System Selection
    if st.session_state.documents_processed:
        st.markdown("---")
        st.header("üñ•Ô∏è System Selection")
        
        st.write("**Enter System ID to analyze:**")
        selected_system = st.text_input(
            "System ID",
            value=st.session_state.selected_system_id,
            placeholder="Enter system ID (e.g., GDP, P01, PRD, DEV)",
            help="Enter a specific SAP system ID to focus the analysis (GDP, P01, etc.)",
            key="system_id_input"
        )
        
        st.session_state.selected_system_id = selected_system
        
        if selected_system and selected_system.strip():
            st.info(f"üñ•Ô∏è Analysis will focus on system: **{selected_system.strip().upper()}**")
        else:
            st.info("‚ÑπÔ∏è Leave empty to analyze all systems in the documents")
    
    # Search section
    if st.session_state.documents_processed:
        st.markdown("---")
        st.header("üîç Search & Analysis")
        
        # Query input
        query = st.text_area(
            "What would you like to know about your SAP documents?",
            height=100,
            placeholder="Example: What are the critical performance issues mentioned in the Early Watch report?"
        )
        
        # Search button
        if st.button("üîç Search Documents", type="primary", disabled=not query.strip()):
            if query.strip():
                with st.spinner("Searching and analyzing documents..."):
                    # Mock analysis results
                    st.markdown("---")
                    st.header("üìä Analysis Results")
                    
                    st.subheader("üéØ Overall AI Analysis")
                    st.write("This is a mock analysis. Configure OpenAI API key for real AI analysis.")
                    
                    # Mock system summaries
                    summary_generator = SystemSummaryGenerator()
                    mock_docs = [Document(page_content="Mock document content", metadata={})]
                    
                    if st.session_state.selected_system_id:
                        system_id = st.session_state.selected_system_id.strip().upper()
                        summary = summary_generator._generate_real_summary_for_system(system_id, mock_docs)
                        
                        st.subheader(f"üñ•Ô∏è System {system_id} Analysis")
                        
                        # Health status
                        health_color = {
                            "HEALTHY": "green",
                            "WARNING": "orange", 
                            "CRITICAL": "red"
                        }.get(summary["overall_health"], "gray")
                        
                        st.markdown(f"**Health Status:** :{health_color}[{summary['overall_health']}]")
                        
                        # Critical alerts
                        if summary["critical_alerts"]:
                            st.subheader("üö® Critical Alerts")
                            for alert in summary["critical_alerts"]:
                                st.write(f"‚Ä¢ {alert}")
                        
                        # Recommendations
                        if summary["recommendations"]:
                            st.subheader("üí° Recommendations")
                            for rec in summary["recommendations"]:
                                st.write(f"‚Ä¢ {rec}")
                        
                        # Metrics
                        if summary["key_metrics"]:
                            st.subheader("üìä Key Metrics")
                            for metric, value in summary["key_metrics"].items():
                                st.write(f"‚Ä¢ {metric}: {value}")
                    else:
                        st.info("Please select a system ID to see detailed analysis.")
                    
                    st.success("‚úÖ Analysis completed!")

if __name__ == "__main__":
    main() 