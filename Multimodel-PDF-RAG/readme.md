# ğŸ“„ Multimodal PDF RAG Pipeline

This project implements an end-to-end Retrieval-Augmented Generation (RAG) pipeline that extracts text from PDFs, semantically chunks and embeds the content, stores it in OpenSearch, and generates intelligent answers to user queries using OpenAI's GPT-4o model. The final response is saved as a DOCX document.

## ğŸš€ Features

- ğŸ“¥ **PDF Text Extraction**: Loads academic papers and extracts their content.
- âœ‚ï¸ **Semantic Chunking**: Uses language-aware chunking to preserve context.
- ğŸ§  **Embedding**: Uses `text-embedding-ada-002` for semantic representation.
- ğŸ” **OpenSearch Vector Storage**: Stores and indexes embeddings for fast retrieval.
- ğŸ’¬ **LLM-Powered Q&A**: GPT-4o generates accurate, structured responses.
- ğŸ“„ **DOCX Output**: Saves generated answers in a Word document.

## ğŸ§¾ Project Structure

```
Multimodel-PDF-RAG/
â”œâ”€â”€ .env                       # API keys and config
â”œâ”€â”€ app.py                    # Main pipeline script
â”œâ”€â”€ attention.pdf             # Sample input PDF
â”œâ”€â”€ multimodel_pdfRAG.ipynb   # Jupyter exploration notebook
â”œâ”€â”€ readme.md                 # ğŸ“˜ Youâ€™re here!
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ response.docx             # Generated LLM output
```

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/Multimodel-PDF-RAG.git
cd Multimodel-PDF-RAG
```

### 2. Set up Python environment

```bash
python -m venv venv
source venv/bin/activate    # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 3. Create `.env` file

```ini
OPENAI_API_KEY=your_openai_key
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_INDEX=pdf_chunks
```

### 4. Start OpenSearch via Docker

```bash
docker run -d --name opensearch -p 9200:9200 -p 9600:9600 \
  -e "discovery.type=single-node" \
  -e "plugins.security.disabled=true" \
  -e OPENSEARCH_INITIAL_ADMIN_PASSWORD=YourStrongPassword \
  opensearchproject/opensearch:2.13.0
```

### 5. Run the pipeline

```bash
python app.py
```

## ğŸ§ª Example Query

The current pipeline uses the paper **"Attention Is All You Need"** and answers:

> _"Can you explain the core idea behind the self-attention mechanism proposed in the paper?"_

Result is saved to `response.docx`.

## ğŸ› ï¸ Dependencies

Key libraries used:
- `langchain`
- `openai`
- `opensearch-py`
- `python-docx`
- `PyMuPDF`
- `python-dotenv`

Install them all via:

```bash
pip install -r requirements.txt
```

## ğŸ“Œ TODO

- [ ] Add UI using Streamlit or Gradio
- [ ] Add chart/image extraction support
- [ ] Support for multi-file uploads
- [ ] Add unit tests

## ğŸ“„ License

MIT License

